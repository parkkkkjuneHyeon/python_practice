# 02. Multiple Linear Regression

### 원 핫 인코딩


```python
import pandas as pd
dataset = pd.read_csv("MultipleLinearRegressionData.csv")
x = dataset.iloc[:, :-1].values
y = dataset.iloc[:, -1].values
```


```python
x
```




    array([[0.5, 3, 'Home'],
           [1.2, 4, 'Library'],
           [1.8, 2, 'Cafe'],
           [2.4, 0, 'Cafe'],
           [2.6, 2, 'Home'],
           [3.2, 0, 'Home'],
           [3.9, 0, 'Library'],
           [4.4, 0, 'Library'],
           [4.5, 5, 'Home'],
           [5.0, 1, 'Cafe'],
           [5.3, 2, 'Cafe'],
           [5.8, 0, 'Cafe'],
           [6.0, 3, 'Library'],
           [6.1, 1, 'Cafe'],
           [6.2, 1, 'Library'],
           [6.9, 4, 'Home'],
           [7.2, 2, 'Cafe'],
           [8.4, 1, 'Home'],
           [8.6, 1, 'Library'],
           [10.0, 0, 'Library']], dtype=object)




```python
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import OneHotEncoder
ct = ColumnTransformer(transformers=[('encoder',OneHotEncoder(drop='first'), [2])], remainder='passthrough')
x = ct.fit_transform(x)
x
# 1 0 : home
# 0 1 : Library
# 0 0 : cafe
```




    array([[1.0, 0.0, 0.5, 3],
           [0.0, 1.0, 1.2, 4],
           [0.0, 0.0, 1.8, 2],
           [0.0, 0.0, 2.4, 0],
           [1.0, 0.0, 2.6, 2],
           [1.0, 0.0, 3.2, 0],
           [0.0, 1.0, 3.9, 0],
           [0.0, 1.0, 4.4, 0],
           [1.0, 0.0, 4.5, 5],
           [0.0, 0.0, 5.0, 1],
           [0.0, 0.0, 5.3, 2],
           [0.0, 0.0, 5.8, 0],
           [0.0, 1.0, 6.0, 3],
           [0.0, 0.0, 6.1, 1],
           [0.0, 1.0, 6.2, 1],
           [1.0, 0.0, 6.9, 4],
           [0.0, 0.0, 7.2, 2],
           [1.0, 0.0, 8.4, 1],
           [0.0, 1.0, 8.6, 1],
           [0.0, 1.0, 10.0, 0]], dtype=object)



### 데이터 세트 분리


```python
from sklearn.model_selection import train_test_split
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=0)
```

### 학습(다중 선형 회귀)


```python
from sklearn.linear_model import LinearRegression
reg = LinearRegression() #객체 생성
reg.fit(x_train, y_train)
y_pred = reg.predict(x_test)
```

### 예측 값과 실제 값 비교 (테스트 세트)


```python
y_pred
```




    array([ 92.15457859,  10.23753043, 108.36245302,  38.14675204])




```python
y_test
```




    array([ 90,   8, 100,  38])




```python
# x_test 에 대한 y_pred는 예측 값이고 x_test에 대한 y_test는 실제 값
```


```python
reg.coef_
```




    array([-5.82712824, -1.04450647, 10.40419528, -1.64200104])




```python
reg.intercept_
```




    5.365006706544733



### 모델 평가


```python
reg.score(x_train, y_train) # 훈련세트
```




    0.9623352565265528




```python
reg.score(x_test, y_test) # 테스트 세트
```




    0.9859956178877444



### 다양한 평가 지표(회귀 모델)

1. MAE(Mean Absolute Error) : (실제 값과 예측 값) 차이의 절대값
1. MSE(Mean Squared Error) : 차이의 제곱
1. RMSE(Root Mean Squared Error) : 차이의 제곱에 루트
1. R2 : 결정 계수
   > R2는 1에 가까울수록, 나머지는 0에 가까울수록 좋음


```python
from sklearn.metrics import mean_absolute_error
mean_absolute_error(y_test, y_pred) # 실제 값, 예측 값 # MAE
```




    3.2253285188288117




```python
from sklearn.metrics import mean_squared_error
mean_squared_error(y_test, y_pred) # 실제 값, 예측 값 # MSE
```




    19.9002269815152




```python
# from sklearn.metrics import mean_squared_error
# mean_squared_error(y_test, y_pred, squared=False) #RMSE #deprecated됨
# root_mean_squared_error 이걸로 바꿈
```


```python
from sklearn.metrics import root_mean_squared_error
root_mean_squared_error(y_test, y_pred) # 실제 값, 예측 값 #RMSE
```




    4.460967045553598




```python
from sklearn.metrics import r2_score
r2_score(y_test, y_pred)
```




    0.9859956178877444


